<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Async Stream RSS Feed]]></title><description><![CDATA[Async Stream RSS Feed]]></description><link>https://hellerstein.io/blog</link><generator>GatsbyJS</generator><lastBuildDate>Mon, 30 Jun 2025 01:22:43 GMT</lastBuildDate><item><title><![CDATA[Tips on Research]]></title><description><![CDATA[As a complement to my last post, I thought I'd write a follow-up with some constructive advice. No point complaining about negativity if you…]]></description><link>https://hellerstein.io/blog/research-tips/</link><guid isPermaLink="false">https://hellerstein.io/blog/research-tips/</guid><pubDate>Fri, 27 Jun 2025 00:00:00 GMT</pubDate><content:encoded>
As a complement to my last post, I thought I&apos;d write a follow-up with some constructive advice. 
No point complaining about negativity if you don&apos;t offer some positive alternatives!

# Five Tips for Doing Your Best Research

Rather than opine about research topics, which are always changing, I thought I&apos;d offer advice on research processes. No doubt a lot of this is conventional wisdom, but I came to these conclusions based on my own career experience. Maybe some of this will be useful to those of you who are earlier on in your journey. Your mileage may vary.


1. **Follow Your Muse, but Evaluate Humbly**. Pursue topics that fascinate you; the best work comes from enthusiasm. But also build in mechanisms that force you to be clear-headed about assessing the impact of your work over time. Evaluate on a timescale that suits your career and work (5-year windows align well with PhD student lifecycles), and humbly move on from topics where the impact isn&apos;t what you wanted. Time spent in industry—especially entrepreneurship—is helpful in learning this discipline; the market is an efficient (heartless!) teacher of lessons in adaptability and humility, as anyone whose startup has &quot;pivoted&quot; will share. Changing course can be scary, but sometimes it sets you free to shine again.

2. **Explore and Exploit**: After my first few years in research, I started deliberately trying to invest my research time in a portfolio of a few &quot;long plays&quot; (in my case, applying declarative/dataflow programming to a variety of other domains) and a larger number of shorter but diverse excursions. Reinforcement learning folks might call this &quot;explore vs. exploit&quot;, and clearly one should do some of both. Connecting back to the previous point, it&apos;s the long plays that benefit the most from deliberate reflection; the short ones have agility built in.

3. **Pick Topics that Leverage Your Working Style**: Pick topic areas that favor a research style that fits your personality. For example, working on AI-related topics right now demands that you produce a lot of quick-fire results in a tightly competitive arena. That requires an restless competitive streak: reading a ton, being quick to change, and doing research in relatively short bites on very popular topics. By contrast, meaningful systems work requires an investment of many years of engineering and teamwork, during which there will be fallow periods of publication. In that space, you need patience, good taste and self-confidence, because you don&apos;t get to change your mind nearly as often. There&apos;s no right answer here—you might enjoy a mixture, and one style is not inherently better than another. But it&apos;s good to make sure that your personal working style matches your topic selection. In your early days, finding role models in the literature can help—again, one role model may be quite different from another, so choose what appeals to you and reassess over time.

4. **Collaborate with Complementary Experts**. It&apos;s good intellectual nutrition to collaborate with experts in a variety of other fields. A lot of the best research opportunities are at the seams between traditional fields, and it&apos;s more educational and fun to work with people who know and think about things different than your experience.
For faculty, I suggest spending ~5 years co-advising Ph.D. students with people in another field, whether that&apos;s across or outside CS. Then consider trying a new collaboration in a different field thereafter. 
Doing this will broaden your horizons, and teach you more about your own strengths: the ones that come from your education in your home field, and the ones that come from your personal research style and talents.

5. **For Topic Selection, Do Your (Qualitative) Research**. This is maybe the least common advice in this list. To choose important problems—especially in user-facing areas—consider learning how to do qualitative research methods like interview studies, to figure out empirically what problems will have impact. I&apos;ve been involved in doing this twice (once for [Enterprise Data Analytics](http://vis.stanford.edu/files/2012-EnterpriseAnalysisInterviews-VAST.pdf), and more recently for [Machine Learning Engineering](https://dl.acm.org/doi/abs/10.1145/3653697)). In both cases, the interview studies led to interesting and highly relevant follow-on constructive work, and the papers describing the studies and results were themselves well received: both won awards. Be aware: this is a lot of work to do well! (To be clear, in the cases above that work was not done by me—it was done by amazing students like [Sean Kandel](https://en.wikipedia.org/wiki/Sean_Kandel), [Rolando Garcia](https://rlnsanz.github.io/) and [Shreya Shankar](https://www.sh-reya.com/)).  Note that versions of this approach are now standard practice for entrepreneurs, and that&apos;s an area where we can learn from industry practices as well as social scientists. See the book [The Mom Test](https://www.momtestbook.com/) for a distilled discussion.

# Caveat
I&apos;ll close with a standard warning I give when people ask me for advice on starting companies. Most entrepreneurs wildly overfit their advice to their own narrow experience. Some folks who dish out advice are more self-aware about that than others. The overfitting is more extreme in the startup world than academia, but the theme remains. 

So... take my advice for what it&apos;s worth (hint: this blog is free!) and go ask a lot of other people for theirs too.
</content:encoded></item><item><title><![CDATA[An Optimist's Reflection on SIGMOD]]></title><description><![CDATA[I write this note on my way home from the annual ACM SIGMOD conference, one of the top venues for data management research. In this post I…]]></description><link>https://hellerstein.io/blog/sigmod-optimism/</link><guid isPermaLink="false">https://hellerstein.io/blog/sigmod-optimism/</guid><pubDate>Fri, 27 Jun 2025 00:00:00 GMT</pubDate><content:encoded>I write this note on my way home from the annual [ACM SIGMOD](https://2025.sigmod.org) conference,
one of the top venues for data management research. In this post I want to reflect on
one of the best-attended sessions, a [panel discussion](https://arxiv.org/abs/2504.08948v1) 
that continued what I think is a sorry tradition of needless negativity for our burgeoning field.

## Starting Positive
Before I get into that, though, let me say that in general I thought this year&apos;s conference was great! 
I am no doubt biased, having spent many many hours leading the program committee with my wonderful co-Chair 
and friend [Azza Abouzied](https://azzaabouzied.com/); I&apos;d like to think that time was well spent. 
Also, numbers for submissions, acceptances, and even attendance were all way up this year—things continue 
to heat up despite the challenges with visas, geopolitics and funding.

Meanwhile, at the conference I got genuinely 
excited by new ideas on a bunch of occasions. Some of the papers this year seem to
crack open big long-standing problems—especially in the area of [Query Optimization](https://2025.sigmod.org/program_full_detail.shtml#sigmod_research_9__query_optimization),
a longstanding interest of mine. We may be at a pivot point in that 50-year-old grand challenge!

On a personal level I actually find the hubbub of conferences a bit overwhelming, but they do get my brain juices
flowing. And it was good to see old friends, reinforce connections, and talk with new people. I also 
had good fun playing the plastic cornet to mark the ends of the breaks. (Points to folks who  
identify the names of some of the musical excerpts in the comments below!)

## Another Eeyore Panel...Sigh
This year&apos;s SIGMOD, once again, featured a very well-attended, soul-searching
(read: self-flagellating)
panel on the direction and value of academic research in our field.
The panel followed the form of a recurring shtick in our community: stirring discussion 
by positing a crisis of irrelevance. 

Mike Stonebraker used to be the main culprit of these panels,
trying to provoke conversation by saying things like &quot;my VC friends think academic computer
science is like a beached whale. Discuss.&quot; Mike is a hero, but I never thought this was one of his
better leadership strategies—especially with respect to encouraging 
young people entering the field.

This year&apos;s panel was more diplomatically managed by two emerging leaders 
who I admire a lot, [Eugene Wu](http://www.cs.columbia.edu/~ewu/) and [Raul Castro Fernandez](https://raulcastrofernandez.com/). But the 
spirit and structure was familiar. Panelists were encouraged to make &quot;provocative&quot;
assertions, which repeatedly included things like &quot;data stakeholders don&apos;t want to buy what we&apos;re selling&quot; and
&quot;database systems are already fast, so stop working on performance&quot;. 

For both of these, at face value the answer is clearly &quot;Duh... No!&quot;, with billions of 
dollars in revenue and cost-savings as evidence. Of course there was a kernel of nuanced 
useful advice in these statements (&quot;be responsive to a wider variety of user needs&quot;, &quot;we can focus on more
topics than performance&quot;), but it was buried in a pile of polemic hogwash encouraged
by the format.

These panels frustrate me. They 
inject negativity and false narratives into the discourse in the name of being
&quot;provocative&quot;, and I get 
impatient because the time spent debating the foolishness could be devoted to far 
more constructive purposes.

## Don&apos;t Worry, Be Happy! 🤠

For my young colleagues who work on data management research, here&apos;s the good news, and 
the *truth:*  data management is an especially rich environment to build a career.
To begin with, there are plenty of well-defined, important and challenging technical problems 
right in front of our noses. Many of these problems have clear economic benefit to established 
vendors, so you can find out about them pretty easily, and do work that gets quick recognition.
Whether these are longstanding problems to be chipped away at, or perennial challenges that keep
shifting with workloads or tech trends, there&apos;s no shortage of well-known topics where you can make 
your name and make a big difference.

Even better: from there, the upside potential is much higher. If history is any guide, there will
be an ongoing stream of unexpected new directions in data management, many of which
will be career-defining. As you gain confidence, go explore! Dream big! Think outside the box!
Choose your cliche...the point is, in the data field the odds of outsized success are bigger than
in most scientific and engineering disciplines. Frankly, we&apos;re spoiled with relevance and opportunity.

And to my senior colleagues let me say this: Enough with the Chicken-Licken-meets-Eeyore act.
Spread some sunshine to the junior folks. To rattle off one more cliche: Lead, Follow or Get Out of the Way!

In the spirit of being constructive, in my next post I&apos;ll share some actionable ideas that I&apos;ve 
found useful for choosing impactful and personally rewarding research.
</content:encoded></item><item><title><![CDATA[CRDTs #4: Convergence, Determinism, Lower Bounds and Inflation]]></title><description><![CDATA[The CRDT literature sometimes leaves room for mathematical ambiguity. Maybe because the bulk of the work tends to be targeted at systems…]]></description><link>https://hellerstein.io/blog/crdt-inflationary/</link><guid isPermaLink="false">https://hellerstein.io/blog/crdt-inflationary/</guid><pubDate>Thu, 29 May 2025 00:00:00 GMT</pubDate><content:encoded>import Callout from &apos;../../../src/components/Callout&apos;
import { withPrefix } from &quot;gatsby&quot;


The CRDT literature sometimes leaves room for mathematical ambiguity. Maybe because the bulk of the work tends to be targeted at systems researchers and developers, like a lot of work on eventual consistency.

The discussion below untangles three subtle but important ideas in CRDT design, which turn out to be interrelated:

1. Determinism vs Convergence guarantees
2. Early `read`s: lower bounds or not?
3. Algebraic property requirements for `update` functions.

&lt;Callout type=&quot;warning&quot;&gt;
The CRDT guarantee of *strong eventual consistency does **not** guarantee determinism!*
If you want your CRDTs to be deterministic, or you want to treat CRDT `read`s as lower bounds, then your `update` functions must be **inflationary**.
&lt;/Callout&gt;

&gt; This is the 4th post in a [series](../crdt-intro/) I&apos;m doing on CRDTs. This one is a bit more technical and narrow than my previous CRDT posts, but practitioners should still know about the main conclusions. This post also contains a small formal result that seems novel -- Strong Eventual Consistency does not guarantee determinism! I&apos;d be curious to hear about prior work that makes this point.

---

## Definitions First

Before we get into the details, let&apos;s be a bit careful with our terminology. I&apos;ll assume you&apos;ve seen CRDTs before, but I&apos;ll review the key points while trying to keep this breezy.

### Join Semi-Lattices

You likely remember that CRDTs are related to *lattices* in abstract algebra. Let&apos;s review that.

Let’s suppose we have a set of possible states $S$, equipped with a **join operator** $\sqcup: S \times S \to S$. The join is required to satisfy three properties:
* **Idempotent**: $x \sqcup x = x$
* **Commutative**: $x \sqcup y = y \sqcup x$
* **Associative**: $x \sqcup (y \sqcup z) = (x \sqcup y) \sqcup z$

If you have a set of states and a binary operator satisfying these properties, you have a **join-semilattice**.

From this operator, we can define a **partial order**:

$$
x \leq y \quad \text{iff} \quad x \sqcup y = y
$$

This means that applying join never forgets anything. It only moves “upward” in the order induced by join.

### **From Join Semi-Lattices to CRDTs**

A CRDT is essentially a replicated join semi-lattice. 
To the core mathematical definition we add one more API, an **`update` function** that mutates the state of the CRDT (while of course staying within the state space $S$).  As we&apos;ll see below, these functions can be the source of nondeterminism depending on their algebraic properties. Also, the CRDT literature tends to refer to the join operator as `merge`. (That works for me, as it disambiguates the CRDT term from the unrelated relational join operator from databases.)

Next, we assume an asynchronous **network dissemination service**  that periodically sends a snapshot of one node&apos;s state to another. When state arrives at a destination node, its local CRDT state is mutated to reflect the `merge` of the current state with the message. 
We&apos;ll assume that every node eventually `merge`s data from every other node directly or indirectly (transitively).

That&apos;s all we need, at the level of detail we&apos;ll pursue here. However, the literature on CRDTs typically highlights a subclass of CRDTs called &quot;op-based&quot; CRDTs. You can read about those in an [earlier post](../crdt-turtles) and I&apos;ll have more to say about them [below](#op-based).

Given this background, let’s move on to define a key property of functions on the lattice domain.

### Inflationary
We say that a function $f:S \rightarrow S$ over an ordered domain $S$ is **inflationary** if its output is never smaller than its input:
$$
x \leq f(x)
$$

For CRDT discussion, we assume the domain $S$ is the same as that of our semi-lattice, and the partial order $\leq$  is the one from our semi-lattice definition. Inflationary functions never take us &quot;down&quot; in the lattice order.


&lt;Callout type=&quot;info&quot;&gt;
Let’s start with something reassuring: the join operator $x \sqcup y$ is always inflationary in each of its arguments.
&lt;/Callout&gt;

Why?
$x \leq x \sqcup y$ because $x \sqcup y$ is an upper bound for $x$.

This is one reason why many CRDT papers don’t emphasize inflationarity: they tend to focus on `merge` operations, and `merge` ($\sqcup$) satisfies the property automatically.

Our issue is going to be the `update` function each node may run between `merge`s. More on that shortly.

But first, let&apos;s define the standard guarantee that CRDTs are designed to provide.


### Strong Eventual Consistency (SEC)

The canonical correctness guarantee for CRDTs is **Strong Eventual Consistency (SEC)**, as defined by [Shapiro et al](https://link.springer.com/chapter/10.1007/978-3-642-24550-3_29). It requires that, eventually, all replicas converge to the same state, provided they have seen the same set of `update`s.

The SEC condition includes three properties:

1. **Eventual delivery**: All `update`s eventually reach all replicas.
2. **Termination**: All operations eventually complete.
3. **Strong convergence**: If two replicas have received the same set of `update`s, they will reach the same state.

Note that SEC says nothing about ordering of operations; in particular it **does not constrain the interleaving of `update` and `merge`**. Given that dissemination is assumed to be asynchronous, a replica might send its current state before or after applying an `update`. We’ll see how this matters next.

---

## SEC Does Not Guarantee Determinism
We tend to think of convergence as a property that avoids non-determinism: after all, in a convergent replica system, all the replicas agree on the outcome. But that doesn&apos;t actually mean that they agree on a *deterministic* outcome!

As defined, Strong Eventual Consistency only says that replicas converge *within* a run. It says nothing about whether different executions — with the same set of `updates` and nodes — produce the same final result.

Consider the following function:

$$
\text{DropTop}(x) = \begin{cases}
  a &amp; \text{if } x = \top \\
  x &amp; \text{otherwise}
\end{cases}
$$

The $\top$ (&quot;top&quot;) symbol is the standard lattice notation for topmost state in a finite lattice (i.e. the unique join of all the states).

$\text{DropTop}$ is not inflationary: it &quot;drops&quot; from $\top$ to a lower value $a$. If a user applies it once at node `A`, the final result depends on whether `A` sends its state to `B` *before or after* applying the `update`.

**Example: Two Possible Outcomes**

Let $S = \{\bot, a, \top\}$, with $\bot &lt; a &lt; \top$.

* Node A starts at $\top$
* Node B starts at $\bot$
* A single user applies $\text{DropTop}$ once on node A

&lt;div className=&quot;diagram-two-floats&quot;&gt;
  &lt;div className=&quot;diagram-float&quot;&gt;
    &lt;img src={withPrefix(&quot;/img/crdt-run1.svg&quot;)} alt=&quot;Outcome 1&quot; style={{ width: &quot;85%&quot;, display: &quot;block&quot; }} /&gt;
    &lt;div className=&quot;diagram-caption&quot;&gt;Run 1&lt;/div&gt;
  &lt;/div&gt;
  &lt;div className=&quot;diagram-float&quot;&gt;
    &lt;img src={withPrefix(&quot;/img/crdt-run2.svg&quot;)} alt=&quot;Outcome 2&quot; style={{ width: &quot;85%&quot;, display: &quot;block&quot; }} /&gt;
    &lt;div className=&quot;diagram-caption&quot;&gt;Run 2&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

**Run 1**: send first, then `update`

* A **sends** $\top$ to B
* B **merges**: $\bot \sqcup \top = \top$
* A **applies** $\text{DropTop}: \top \mapsto a$
* B **sends** $\top$ to A
* A **merges**: $a \sqcup \top = \top$
* Final state: A = $\top$, B = $\top$

**Run 2**: `update` first, then send
* A **applies** $\text{DropTop}: \top \mapsto a$
* A **sends** $a$ to B
* B **merges**: $\bot \sqcup a = a$
* Final state: A = $a$, B = $a$

Same updates. Same nodes. Same messages. Different orders. Two different converged states.

---

## Inflationarity is Needed for Deterministic Convergence

As we&apos;ve seen, non-inflationary functions like $\text{DropTop}$  may non-deterministically drive the CRDT into one of many possible converged states, which depend on the interleaving of `update`s and messages.

If all `update`s are inflationary, then once a state has moved &quot;up&quot; the lattice, it never moves back down — and that ensures:

* Each replica&apos;s state moves up the lattice.
* Merging always moves replicas up in the lattice.
* The final state is the least upper bound of all `update`s.

That last point ensures **determinism**: the final result depends only on the set of `update`s, not their timing.

&lt;Callout type=&quot;warning&quot;&gt;
**Inflationary `update`s are required for deterministic convergence in CRDTs.**
&lt;/Callout&gt;
Non-inflationary `update`s will still converge to some common state, but the choice of converged state will be non-deterministic.

---

## Non-Inflationary Updates Spoil Lower Bounds
In [the previous post](../crdt-dont-read) I talked about how it&apos;s unsafe to `read` the naked state of a CRDT, but at least 
a &quot;well-behaved&quot; CRDT provides lower bounds. Well, in addition to providing non-deterministic outcomes,
**non-inflationary `update`s are &quot;ill-behaved&quot; and do *not* provide lower bounds**.

Imagine you&apos;re writing application logic that reads from a CRDT value during execution.

If the `update` function is inflationary, you have a guarantee: the current state always provides a **lower bound** of the final state. That makes it safe to make assumptions like:

* &quot;This user will never lose this permission.&quot;
* &quot;This counter will only increase from here.&quot;

But if `update`s are **not** inflationary, those assumptions no longer hold. You might see a high value now — and a lower one later — because your node applied a non-inflationary `update`.

That means your application can&apos;t treat CRDT reads as stable observations in any sense. It must treat every intermediate value as potentially temporary.

&lt;Callout type=&quot;danger&quot;&gt;
When using non-inflationary `update` functions, CRDT `read` values can be completely arbitrary. Inflationary `update` ensures that CRDT `read` is a lower bound on the final converged state, which is a common assumption in the CRDT literature.
&lt;/Callout&gt;

&lt;br/&gt;&lt;br/&gt;

### Ensuring Inflationarity
There is a simple hack to ensure inflationarity, by changing the implementation of the `update` API, or removing it entirely.

The change is as follows. When a user invokes `update(x)`, we do not directly mutate the CRDT state to `x`; rather, we mutate the state to `merge(update(x))`. Because `merge` is inflationary (as discussed above), the effect of updates in this implementation is always inflationary.
The result is determinism and guaranteed lower bounds, at the cost of a slightly surprising instant/&quot;local&quot; effect from `update`.

If you want the contract with the CRDT programmer to be more explicit, you can simply remove `update` from the API and force developers to invoke `merge` locally. This is nearly the same as the above design, except for type signatures:
- `merge`$: S \to S$
- `update`$: U \to (S \to S)$ 

That is, `update` can take values from some other domain $U$ and map them into mutations to $S$. Removing the `update` API  requires programmers to do that mapping at application level, but is more transparent about a semantics that &quot;`merge` always happens immediately to ensure inflationarity&quot;.


---

# Additional Technical Material
Just in case the above wasn&apos;t enough for you, here are a few more points that may be of interest to aficionados!

## &lt;a id=&quot;op-based&quot;&gt; &lt;/a&gt; Brief Note: Op-Based CRDTs are Deterministic

In [a previous post](../crdt-turtles#op-based) I explained how a fully-specified Op-Based CRDT is a join semi-lattice of a particular kind: a grow-only set lattice over the powerset $P(C \times O)$ containing tuples $(c_i, o_i)$, each comprised of a **causal context lattice** of type $C$ and a value from a domain of mutually commutative operations $O$. The &quot;causal context&quot; is typically a vector clock or DAG that dictates which of the other items in the set precede this one in a partial order.

At a gloss, the `update` function of an op-based CRDT takes as input an op $o_i \in O$ and does the following:

1. increment the local causal context to $c_{t+1}$ (e.g. a new vector clock value with the local nodeId&apos;s value incremented) 
2. add a tuple $(c_{t+1}, o_i)$ to the local set

This is clearly inflationary. From the semi-lattice perspective, we are simply adding an element to a set, so the result of update is a &quot;bigger&quot; set. Similarly, the underlying causal history is growing: 1 node is added, some precedences are added to the causal context, and nothing is taken away.

There are some nuances around &quot;expiring&quot; history from the partial order of ops that I discuss in that same post; they do not change the inflationary nature of Op-Based CRDTs.

&lt;Callout type=&quot;info&quot;&gt;
**Op-Based CRDTs are deterministic**, because their updates are inflationary by definition.
&lt;/Callout&gt;

---
## What About Monotonicity?
If you know of me from the CALM Conjecture, you might be suprised that I haven&apos;t used the &quot;M&quot; word yet: **monotonicity**. In fact, many authors in this space—myself included—have been imprecise in when we use monotonicity vs inflationarity. Let me clear this up here in this context.

We should start with crisp definitions.

### Monotonicity

$$
x \leq y \quad \Rightarrow \quad f(x) \leq f(y)
$$

Monotonicity is a **relational property**: it relates how the ordering on inputs maps to the ordering on outputs. At a gloss, it ensures that the more you put into the input, the more you get in the output.

### Inflationarity

$$
x \leq f(x)
$$

Inflationarity is a **pointwise property**: it compares each input directly to its own output. It ensures that applying the function doesn&apos;t discard information from its input.

### So What?
Well first off, you should know that these two properties are orthogonal: there are functions that are neither, either, or both.

Going back to our $\text{DropTop}$ function. Recall the definition:

$$
\text{DropTop}(x) = \begin{cases}
  a &amp; \text{if } x = \top \\
  x &amp; \text{otherwise}
\end{cases}
$$

This is clearly non-inflationary, assuming $a \ne \top$.

&lt;div className=&quot;diagram-float&quot;&gt;
    &lt;img src={withPrefix(&quot;/img/3-element.svg&quot;)} 
    alt=&quot;DropTop on a 3-element domain&quot; 
    style={{ display: &quot;block&quot;, maxHeight: &quot;120px&quot;}} 
    /&gt;
&lt;/div&gt;

Let&apos;s consider $\text{DropTop}$ over the domain $S = \{\bot, a, \top\}$ where $\bot \lt a \lt \top$. In this case, we have a non-inflationary function that *is* monotonic!  Let&apos;s work out the details:

- $\bot \leq a$ and $\text{DropTop}(\bot) \leq \text{DropTop}(a)$
- $a \leq \top$ and $\text{DropTop}(a)\leq \text{DropTop}(\top)$, because $\text{DropTop}(a) = \text{DropTop}(\top) = a$.


We&apos;ve seen above that $\text{DropTop}$ leads to non-determinism over the totally ordered domain *even though* it is monotonic. 

But here&apos;s a funny thing: consider the same function over the domain $S = \{\bot, a, b, \top\}$, where the join generates a partial order $\bot \leq \{a, b\} \leq \top$:
&lt;div className=&quot;diagram-float&quot;&gt;
    &lt;img src={withPrefix(&quot;/img/4-element.svg&quot;)} 
    alt=&quot;DropTop on a 4-element domain&quot; 
    style={{ display: &quot;block&quot;, maxHeight: &quot;120px&quot;}} 
    /&gt;
&lt;/div&gt;

In this domain, $\text{DropTop}$ is **non-monotonic!**.  To see it, consider that:

- $ b \leq \top$, but $\text{DropTop}(b) \not\leq \text{DropTop}(\top)$ because $\text{DropTop}(\top) = a$, and $a$ and $b$  are incomparable!

The same scenario we used to show that $\text{DropTop}$ leads to non-determinism in the previous totally-ordered domain shows it leads to non-determinism over this partially ordered domain, where it *is non-monotonic*. 

So: one monotonic example, one non-monotonic example. Neither is inflationary, and both lead to non-deterministic outcomes!  The relevant issue in this situation should now be clear: **updates need to be inflationary to achieve deterministic outcomes; monotonicity of update functions is irrelevant to determinism**.

### How Does this Relate to the CALM Theorem?
Great question! First, as a member of the University of California faculty, I&apos;d be happy to change the name to the CALI Theorem if inflation were the key property, rather than monotonicity!

But we should stay CALM.

The &quot;type signatures&quot; of these two terms give us a hint as to when we use them. Inflationarity is a property that only makes sense on functions from a domain to itself (*endofunctions*, if you like fancy math terms). Monotonicity is a property that we can define without regard for the domain and range of a function.

CRDTs are scoped as abstract data types, and hence mostly just capture transformations from state to state within a single domain. Hence inflationarity is an appropriate lens for them.

The CALM Theorem reasons about entire programs, and as such it cannot be defined in terms of inflationarity alone. Usually we want to talk about inflation of inputs to the program over time, and monotonicity of the logic that the program applies to those inputs to produce outputs that may well be in another domain. This is not a new observation; this distinction was made carefully by Ameloot, Neven and van Den Bussche in their [first proof of the CALM Theorem](https://dl.acm.org/doi/10.1145/1989284.1989321).

Returning to CRDTs, it&apos;s easy to show that **semi-lattice join is monotonic** in both inputs. We can also observe that *CRDTs are both inflationary and monotonic in their final, converged outcomes*: if you run a CRDT to convergence on some set of updates $U_1$, and then run it again to convergence on a set of updates $U_2 \geq U_1$, you&apos;ll find the the outcome of the second run is no lower in the lattice than the outcome of the first run—even if your update functions are non-inflationary!

---

## Want More?
This is not the first writing that distinguishes between inflationary and monotonic functions in the context of distributed or parallel computing.

Here are a couple interesting and relevant prior references I&apos;ve found. I&apos;d love to know of others!

[LVars](https://dl.acm.org/doi/10.1145/2502323.2502326) inventor **Lindsey Kuper** has a 2015 blog post, *[What’s the difference between inflationary and monotonic functions?](https://decomposition.al/blog/2015/08/31/whats-the-difference-between-inflationary-and-monotonic-functions/)* that highlights the confusion many have regarding inflationarity and monotonicity, and gives intuitive examples to demonstrate that they are orthogonal properties.

**Almeida et al.** recently published a CRDT survey (*[Computing Surveys, 2023](https://dl.acm.org/doi/10.1145/3695249)*) that includes a discussion of **inflationary** and **monotonic** updates, and argues that prior work erroneously demanded monotonic update functions, when it should have demanded inflationary functions. In fact, as we discuss above, the SEC guarantee of CRDTs does not demand inflationarity or monotonicity of update! Inflationarity is only necessary if we want determinism or lower bounds (monotonicity of `read`). Moreover, their example (page 18) of a monotonic but non-inflationary function is *decrement*, which is a bit confusing: decrement can be inflationary in some contexts (e.g. a countdown timer based on natural numbers with `min` as the `merge` function), but anti-inflationary (&quot;deflationary?&quot;) in other contexts (e.g. a typical integer/`max` counter semi-lattice.) It&apos;s nicer to have an example like $\text{DropTop}$ that is neither inflationary nor anti-inflationary, and which separates inflationarity and monotonicity directly (by simply expanding the domain).

I am not aware of prior CRDT literature that explicitly discusses the idea that inflationarity is a requirement for deterministic convergence under SEC. If you know of such work, please link to it in a comment below, or reach out if you don&apos;t have a github account!

&gt; Thanks to [Conor Power](https://www.linkedin.com/in/conorpower23/) for sparking my interest in this topic and providing sanity checks on early drafts of this post.
</content:encoded></item><item><title><![CDATA[CRDTs #3: Do Not Read!]]></title><description><![CDATA[Ever used a CRDT, thought you were safe, and—boom—you bought a Ferrari you didn't mean to? It could happen to you! The truth is that CRDTs…]]></description><link>https://hellerstein.io/blog/crdt-dont-read/</link><guid isPermaLink="false">https://hellerstein.io/blog/crdt-dont-read/</guid><pubDate>Fri, 23 May 2025 00:00:00 GMT</pubDate><content:encoded>
import Callout from &apos;../../../src/components/Callout&apos;
import { withPrefix } from &quot;gatsby&quot;

Ever used a CRDT, thought you were safe, and—boom—you bought a Ferrari you didn&apos;t mean to? It could happen to you!

The truth is that CRDTs are dangerous to observe: they 
guarantee *eventual consistency*, but you&apos;ll never know when &quot;eventual&quot; arrives.
That gap between what CRDTs promise and what you can safely `read` is generally not 
well protected in CRDT libraries, and it&apos;s exactly where the bugs sneak in.
**It is not safe to `read` a CRDT&apos;s raw state, people!**

What CRDTs *can* offer—*when used properly!*—is **monotonicity**:
the guarantee that once you&apos;ve seen a fact, no future update will contradict it. 
And that&apos;s a powerful basis for providing safe APIs to your CRDTs.

&gt; This is the 3rd post in a [series](../crdt-intro/) I&apos;m doing on CRDTs. This one is particularly for you software engineers out there.
&gt; News you can use.

---

## Takeaways

&lt;Callout type=&quot;danger&quot;&gt;
**Look not at the naked state of thy CRDT!** Encapsulate it, and break that encapsulation 
cautiously ...with plenty of code review and comments!
&lt;/Callout&gt;

&lt;Callout type=&quot;warning&quot;&gt;
**You will never experience eventuality**. Eventual consistency is an abstract concept, not a guarantee you can count on.
&lt;/Callout&gt;

&lt;Callout type=&quot;success&quot;&gt;
**All is not lost!**
The monotonicity of many CRDTs can help, especially via [threshold functions](#threshold-functions).

In general, you&apos;ll need coordination to know when you&apos;re done—use it, sparingly and strategically.
&lt;/Callout&gt;

&lt;Callout type=&quot;info&quot;&gt;
See the [CRDT Survival Guide](#survival-guide) at the end of the post!
&lt;/Callout&gt;
---
## Prologue: ‟Eventual Consistency”
Have you ever asked that age-old question, &quot;Are we there yet?&quot; Eventual consistency promises you&apos;ll eventually get to an agreed-upon value across replicas... but when is &quot;eventual&quot;? Tomorrow? Next year? After you&apos;ve bought a Ferrari you didn&apos;t mean to? 

Werner Vogels [defined eventual consistency like this](https://dl.acm.org/doi/10.1145/1435417.1435432):  
&gt; *If no new updates are made to the object, eventually all accesses will return the last updated value.*

Sounds reassuring, right? And it avoids expensive coordination protocols like Paxos or Two-Phase Commit. 

But here&apos;s the catch: *How do you know there are no new updates?*
In distributed systems, termination detection (i.e. &quot;am I done yet?&quot;) requires knowing:

1. **No node** will issue any new messages.
2. **No messages** are in flight.

In logic, that&apos;s:

$$
\neg\exists n  \; (p(n))
$$

&quot;there does not exist an $n$ where property $p(n)$ holds&quot;. 

Any time you see a $\neg\exists$ (or its doppelganger, $\forall$) in distributed logic, *beware!* One rogue message — *a single counter-example* — can arrive at any time to invalidate the property.

👉 **Termination (&quot;eventuality&quot;) is non-monotonic**. It can be true over a certain set of information, but become false if more data arrives.

The [CALM Theorem](https://cacm.acm.org/research/keeping-calm/) says that eventual consistency without coordination is possible *if and only if* the program specification is monotonic. Thus (via CALM):

👉 **Termination Detection requires Coordination**. 

So ... in coordination-free systems, you can never know when &quot;eventual&quot; has arrived!

&lt;details&gt;
&lt;summary&gt;Click for a review of monotonicity.&lt;/summary&gt;

Given a function $f:S \rightarrow T$, where $S$ and $T$ are ordered domains, we say that $f$ is **monotone** (or **monotonic**) if:

$$
x \le y \implies f(x) \le f(y)
$$

Intuitively, a monotone function *preserves order*: it guarantees that if the input gets &quot;bigger&quot;, then the output gets no smaller.

Monotonicity is often used in logic, where our domains $S$ and $T$ contain sets of facts. Given an input set $x$, a logical function $f$ produces a set of *conclusions*, $f(x)$. If $f$ is monotone, $x \subseteq y \implies f(x) \subseteq f(y)$: that is, $f(y)$ contains all the facts in $f(x)$ and perhaps more. 

In practical terms, if we think of $f$ as a process running over a growing stream of facts, we can say this: *once an output fact is concluded by a monotone function, additional input facts will not invalidate that conclusion*.

You can see why this is useful in a distributed system! 

1. Monotone functions allow for correct, wait-free, streaming computation.
2. For logical monotone functions, the truth of each conclusion is invariant in the face of additional input.
&lt;/details&gt;


---

## 🙋🏾‍♂️ Is Anything Safe Before ‟Eventual&quot; comes?

&lt;Callout type=&quot;danger&quot;&gt;
In general, no! The state of a CRDT could be incomplete and may change.
&lt;/Callout&gt;

This is a common misunderstanding. It&apos;s easy to confuse the formal guarantees of `merge` (which CRDTs provide) with the safety of `read`s (which they absolutely do not). 

If you previously missed this, you are in good company. The danger of `read` is not prominent in online discussion, software packages, or the CRDT literature. Perhaps this post can serve as a warning and a pointer to more subtle discussion in the literature.

Let&apos;s illustrate the problem—and ways to use CRDTs responsibly.

---

### 🚨 Two-Phase Sets: Poster Child of the Problem

A 2-Phase (Add/Remove) Set CRDT maintains two sets:

```rust
struct 2PSet {
    adds: Set&lt;(id, element)&gt;;
    removes: Set&lt;(id, element)&gt;;
}
```

Merges? Safe—just union both sets.

```rust
fn merge(a: &amp;2PSet, b: &amp;2PSet) -&gt; 2PSet {
  2PSet {
    adds: a.adds.union(&amp;b.adds),
    removes: a.removes.union(&amp;b.removes),
  }
}
```

But the `read`?

```rust
fn read(s: &amp;2PSet) -&gt; Set&lt;element&gt; {
  s.adds - s.removes
}
```

This `read` is **non-monotonic**: as `removes` grows, your `read` result *shrinks*. That&apos;s the trap.

So what could go wrong?

#### 🥔 🏎️ The Potato/Ferrari Example
&lt;div className=&quot;diagram-float&quot;&gt;
  &lt;img src={withPrefix(&quot;/img/ferrari-diagonal.svg&quot;)} alt=&quot;CRDT Ferrari Sequence Diagram&quot; style={{ width: &quot;85%&quot;, display: &quot;block&quot; }} /&gt;
&lt;/div&gt;
Here&apos;s an example of what could go wrong, from our [Keep CALM and CRDT On](https://www.vldb.org/pvldb/vol16/p856-power.pdf)  paper:


&gt; While shopping online at RetailCo, you add a potato and a Ferrari to your cart. Reflecting on your finances, you decide to remove the Ferrari, and check out.&lt;br/&gt;

```rust
cart.add(&quot;potato&quot;);
cart.add(&quot;Ferrari&quot;);
cart.remove(&quot;Ferrari&quot;);
cart.checkout();
```

The CRDT-based cart is replicated, and unfortunately replica `B` receives `checkout` before `remove`. It `read`s the cart, and ships you a Ferrari. Boom. &lt;br/&gt;


👉 **Merges are safe; reads are not.** 2P-Sets? Nearly useless for safe reads.
### What about Simpler CRDTs?
You might be saying:

*Well, 2P-sets use a *set difference* operator, which is clearly non-monotonic. The CALM Theorem warned us that non-monotonic operations require coordination for consistency! 
But surely a plain old grow-only set is safe to read? After all, its `read` function looks nice and monotonic!*

&lt;div className=&quot;diagram-float&quot;&gt;
  &lt;img src={withPrefix(&quot;/img/ingredients.svg&quot;)} alt=&quot;CRDT Ingredient Sequence Diagram&quot; style={{ width: &quot;100%&quot;, display: &quot;block&quot; }} /&gt;
&lt;/div&gt;

You&apos;d be right that the `read` is monotonic:
```rust
read(s: GrowOnlySet) -&gt; Set {
  s.adds
}
...
let c = GrowOnlySet.new();
```

And that seems safe locally. But wait until you see the downstream logic:

```rust 
let ingredients = c.read();
if edible(&amp;ingredients) {
  cook(&amp;ingredients);
} else {
  panic!(&quot;InedibleError&quot;);
}
```

Both replicas start out empty—I think we can all agree that the empty set is inedible. 
But imagine replica `A` merges some yummy stuff:
```rust
c.merge([&apos;apples&apos;, &apos;honey&apos;]);
```
We transition from `!edible` to `edible`.

Now suppose replica `B` merges some more stuff:
```rust
c.merge({&apos;bleach&apos;, &apos;Paxos&apos;})
```
Bleach and Paxos both have their uses, but please dont ingest them!  Merging in more stuff transitions replica `A` back from `edible` to `!edible`.
Even though `c` grows monotonically, `edible` is not a monotone function over `c`,
so the result of `edible(c)` toggles from false to true to false at node `A`!

👉 **The general point: even monotonic `read`s can lead to non-monotonic conclusions in downstream code.**

This seems like pretty bad news! But all is not lost. Let&apos;s look at some ways to work with CRDTs that provides
some guard rails.

---
## &lt;a id=&quot;be-safe&quot;&gt;&lt;/a&gt; 🦺 Safety First: Encapsulate CRDT State
To prevent the kinds of surprises we just saw, CRDT state should be *encapsulated*, using a language that supports strong typing. If `read` is offered, it should be marked as `unsafe`.

A compiler *might* allow `read` without `unsafe` *if* it can prove all downstream logic is monotonic. But that&apos;s rare. Monotonicity is undecidable in general.

If you&apos;re in Rust, check out [Hydro](https://hydro.run): we&apos;re working on these issues!


## 👍 Safe, Practical CRDT Usage: Lower Bounds and Threshold Functions

Are there any functions that can safely examine CRDT state? Yes indeed! Monotonicity to the rescue.

Specifically, since the value of a properly-written CRDT should only go up over time, CRDTs give you trustworthy *lower bounds*. Just don&apos;t treat a lower bound as a final answer—a lower bound is a special type,
which you can only compare using `&lt;=`! In particular, you can&apos;t test for equality (`==`) with a lower bound. 

In addition, *you can expose monotone functions on CRDTs* to safely compute on their evolving state. 
Let&apos;s see how.


### &lt;a id=&quot;threshold-functions&quot;&gt;&lt;/a&gt; ✅ Thresholds: Coordination-Free Termination

Some lattices are bounded, which means they have a unique top element ($\top$). Once you hit $\top$, you&apos;re done! As a classic example, consider the boolean lattice with values `{false , true}` and merge function that computes $\vee$ (logical `or`).

**Threshold functions** are boolean functions (i.e. truth predicates) on lattices that exploit this:
- They map from a big (or unbounded) lattice to the boolean lattice
- They are *monotone* functions: as the input gets bigger, the output can never go down -- once `true`, always `true`!
- `true` is $\top$ and *safe to `read`*

Clearly `edible` is not a threshold function. What is a good example? Here are two examples on grow-only set lattices: once true, always true!

```rust
state.len() &gt; 100;
state.contains(&apos;Apple Sauce&apos;);
```

CRDTs and threshold functions can be pretty useful. Even if your full lattice (like a set) has no practical $\top$, your threshold function does! Once you cross that threshold, you can treat the truth value as a stable boolean value—one that will be eventually consistent across nodes. So you can `read` the output of the threshold function safely.

Threshold functions are a common example, but you can safely use any monotone function that maps to any finite, 
ordered type!
But remember: *until* your monotone function hits $\top$ in your output type, you&apos;re still in unsafe territory. 
`Read`s may still change! So threshold functions are only helpful when they become true $(\top)$.

---

## 🧭 So What Should Systems Do?
Realistically, many eventually consistent systems need to use some coordination at some point. And in many cases that&apos;s OK, especially if we can *avoid coordination most of the time*! As my colleague [Natacha Crooks](https://nacrooks.github.io/) said once, &quot;most programs are not monotonic, but most programs are mostly monotonic&quot;. So the trick is to put coordination in its place. 

Here&apos;s some advice as you think about eventual consistency, CRDTs, monotonic programming, and the like:

**1. Coordination is still needed to *know* when you&apos;re done.**  
Use it sparingly! For example, when you&apos;re pretty sure every node is done with a task or session — maybe because some coordination-free threshold has been met — you can employ a round of consensus to detect termination. (Of course if it fails you may have to wait and try again later.)

**2. Don&apos;t trust CRDTs that have non-monotonic `read`s.**  
Non-monotonic `read` methods like that of 2P-sets are *unsafe in any context:* it doesn&apos;t matter what you do downstream, the `read` itself exposes you to non-monotonicity and hence race conditions. 2P-sets and their more complicated sibling, OR-sets, are quite troublesome in that respect.
The only safe way to use them is to do coordination for each `read`—which probably makes 2P-sets no more efficient
than your favorite transactional database!

**3. Embrace strong typing and escape hatches.**
CRDT state should be encapsulated, and methods that expose the state should be marked `unsafe`. Even if the `read` is monotonic, downstream logic may not be. 
There are certainly cases where developers will want to take their non-deterministic chances `read`ing the 
state of a CRDT, and that&apos;s their business! But for purposes of maintainability and code review, risky behavior of that sort should be explicitly flagged in code, just like Rust requires us to flag unsafe memory accesses.

**4. Monotonic thresholds are your friend.**  
Thresholds and other monotone functions enable safe, observable progress without coordination — *if* you expect to hit $\top$.

In summary, I offer this:
### &lt;a id=&quot;survival-guide&quot;&gt;CRDT Survival Guide&lt;/a&gt;

&lt;Callout type=&quot;success&quot;&gt;
**Safe:** `merge` freely, take advantage of threshold functions.
&lt;/Callout&gt;

&lt;Callout type=&quot;warning&quot;&gt;
**Unsafe:** `read` at your own risk.
&lt;/Callout&gt;

&lt;Callout type=&quot;danger&quot;&gt;
**Avoid:** Non-monotonic reads like in 2P-sets.
&lt;/Callout&gt;

&lt;Callout type=&quot;info&quot;&gt;
**Pro Tip:** Treat CRDT state like a radioactive material—encapsulate it, mark `read` as unsafe.
&lt;/Callout&gt;

---

## 🧠 Want More?

If you&apos;re looking for formal research in this space that goes beyond the main CALM Theorem papers, check out these more recent results:

- Conor Power&apos;s recent theoretical work on [Free Termination in ICDT 25](https://drops.dagstuhl.de/storage/00lipics/lipics-vol328-icdt2025/LIPIcs.ICDT.2025.32/LIPIcs.ICDT.2025.32.pdf) goes beyond thresholds 
to identify more cases where you can terminate without coordination. 
- Be aware that researchers have found extensions to the CALM theorem, where global knowledge can allow coordination-free computation in more cases.
The most recent paper in this line of work is from our friends Tim Baccaert and Bas Ketsman in a [PODS 2023](https://dl.acm.org/doi/10.1145/3584372.3588657) paper.
- For original research on threshold functions, see Kuper and Newton&apos;s [LVars](https://dl.acm.org/doi/10.1145/2502323.2502326).

...and stay tuned for the next post on CRDTs&apos; algebraic properties.
</content:encoded></item><item><title><![CDATA[CRDTs #2: Turtles All the Way Down]]></title><link>https://hellerstein.io/blog/crdt-turtles/</link><guid isPermaLink="false">https://hellerstein.io/blog/crdt-turtles/</guid><pubDate>Thu, 22 May 2025 00:00:00 GMT</pubDate><content:encoded>&lt;blockquote class=&quot;quote&quot;&gt;
&lt;p&gt;
After a lecture on cosmology, William James was challenged by a skeptic:  
&lt;/p&gt;

&lt;p&gt;
&quot;Your theories are incorrect. The Earth rests on a turtle,&quot;&lt;br /&gt;
&quot;And what holds up the turtle?&quot; James asked.  &lt;br /&gt;
&quot;Another turtle,&quot; came the reply. &lt;br /&gt;
&quot;And what holds that up?&quot; pressed James.
&lt;/p&gt;

&lt;p&gt;
The skeptic was undeterred:&lt;br /&gt;
&quot;You can&apos;t fool me, sir. It&apos;s turtles all the way down.&quot;
&lt;/p&gt;

&lt;p&gt;
&lt;em&gt;— Anecdote attributed to William James ([via J.R. Ross, 1967](https://en.wikipedia.org/wiki/Turtles_all_the_way_down))&lt;/em&gt;
&lt;/p&gt;
&lt;/blockquote&gt;

*This is the 2nd post in a series of 4 posts I&apos;m doing on CRDTs. Please see the [intro post](../crdt-intro/) for context.*

Modern distributed systems often seem to rest on an stack of turtles.
For every guarantee we make, we seem to rely on a lower-layer assumption. Eventually we&apos;re left wondering: what *is* at the bottom?

CRDTs — *Conflict-Free Replicated Data Types* — are often advertised as a foundation we can finally trust.
They promise convergence of state across machines *without* requiring perfect clocks, global operation ordering, or causal message delivery ... and they do it with math.

But many CRDTs sneak in assumptions that don&apos;t belong. That&apos;s not solid ground. It&apos;s not math. It&apos;s turtles.

In this post, we’ll show how to design CRDT internals properly:

- ✅ Always in terms of a semilattice structure.  

- ✅ Always with clean algebraic reasoning, without hidden dependencies. 

- ✅ With explicit causality lattices included whenever needed. 


This will ensure we&apos;re always using careful reasoning.

*Correct CRDTs are semilattices at bottom.* And that&apos;s math you can count on.

## 🐢 A Principle for CRDTs: Semilattices All the Way Down
Every well-designed CRDT is a **semilattice**.

- ✅ A semilattice defines how information grows and `merge`s.
- ✅ It provides convergence by construction, through clean algebra.

In case you&apos;ve read about a split between so-called &quot;state-based&quot; vs &quot;op-based&quot; CRDTs, you can ignore that for now; it&apos;s a turtlish distraction I will [fill in below](#op-based). Here’s what actually matters:

&gt; A semilattice is:
&gt; - A set of states $S$
&gt; - A `join` function $\sqcup : S \times S \to S$ that must satisfy **commutativity**, **associativity**, and **idempotence**. 
&gt; The `join` function induces a partial order:
&gt; $x \leq y \iff x \sqcup y = y$.

When discussing CRDTs, people often use the term `merge` instead of `join`.


CRDTs sometimes add additional &quot;update&quot; operators: 
&gt; `update`$: U \to (S \to S)$ 
`update` takes an input value of type $U$ and uses it to directly mutate the local CRDT&apos;s state.

If all pairs of nodes eventually `merge` state in an associative, commutative and idempotent manner, then eventual convergence of a CRDT is guaranteed — no further assumptions required.

## 🔍 Common CRDT Mistake: Hiding Assumptions
Many CRDT descriptions assume causal message delivery, message uniqueness, or reliable clocks ... but fail to encode these in their semilattices.

🚫 That’s like putting turtles back under the CRDT again!

### ✔️ Design Rule:
&gt; All required assumptions must be **internalized** in the semilattice structure.

- If your algorithm needs causality, encode it.

- If it expires or compresses away state, model that algebraically too, and make sure it respects the rules of a semilattice.

- You can always optimize later (see [below](#building-on-an-existing-turtle)) ... but the math must be sound on its own.

## Case Study: Add/Remove Sets
Let&apos;s walk through a concrete example. A 2-Phase (2P) Set is a simple CRDT that tracks a pair of set-based lattices `(adds, removes)` where `merge` is set-union for each:
- **adds**: `{(id, element)}`
- **removes**: `{(id, timestamp)}` (sometimes referred to as **tombstones**)

The 2P-Set is a **free product** of these two set lattices, which is to say that the 2P-Set `merge` operator  is simply the independent `merge` of 2 **adds** sets, and 2 **removes** sets:

$$
(a_1, r_1) \sqcup (a_2, r_2) =
    (a_1 \sqcup a_2, b_1 \sqcup b_2)
$$



Updates are simple: add an item by inserting into **adds**, delete an item by placing its id and time of deletion into **removes**. All good.

Until... you try to expire tombstoned data to save space.

### Observed-Remove (OR) Sets

The OR-Set CRDT extends 2P-Sets to allow tombstones to be expired, but ... it&apos;s tricky! Let&apos;s walk through it.

A naive scheme for expiring tombstones might work as follows: look at a local wall-clock, and expire ids from **adds** and **removes** whose tombstone timestamps are &quot;older&quot; than a threshold. Turns out that this would be bad! Making this decision based on local time can cause **non-convergent** behavior. 

This is not at all obvious (in fact, ChatGPT happily provided incorrect proofs in both directions!), so I constructed a proof by example.  The basic idea is this: even after all updates have been issued, nodes can pass an item back and forth as a &quot;hot potato&quot; indefinitely, and never converge despite communicating infinitely often! 

&lt;details&gt;
&lt;summary&gt;Click to see a non-convergent OR-Set cycle infinitely.&lt;/summary&gt;
&lt;a href=&quot;../img/divergence_fsm_piechart.png&quot;&gt;
  &lt;img
    src=&quot;../img/divergence_fsm_piechart.png&quot;
    alt=&quot;FSM Divergence Diagram&quot;
  /&gt;
&lt;/a&gt;
&lt;p&gt;
  This diagram shows an oscillating state change cycle -- a single item in an OR-set that uses naive local expiry and never converges, just keeps rotating from state to state forever. Each &apos;pie&apos; represents a &lt;em&gt;global&lt;/em&gt; state of the item, across each of three nodes, &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt; and &lt;code&gt;C&lt;/code&gt;. In each state, each of the machines either has the item only in the adds set (&lt;code&gt;+&lt;/code&gt;), in the adds and removes sets (&lt;code&gt;—&lt;/code&gt;) or in neither (&lt;code&gt;?&lt;/code&gt;). Edges are labeled with state transitions: &lt;code&gt;xp@A&lt;/code&gt; means that the item expired at node &lt;code&gt;A&lt;/code&gt;; &lt;code&gt;B &amp;lt;- A&lt;/code&gt; means that node &lt;code&gt;B&lt;/code&gt; received a copy of the item from node &lt;code&gt;A&lt;/code&gt;.
&lt;/p&gt;
&lt;p&gt;
  Click on the image to zoom if needed.
&lt;/p&gt;
&lt;/details&gt;

#### 🧯 Fix: Explicit Causality
This brings us back to the main point of this post: we need to *explicitly* include information in our OR-set semilattice ... in this case, to support convergent expiry of state. Specifically we can use a nested semilattice to track a **causal context**—e.g. a **version vector**—and use that to determine when it&apos;s safe to expire items:

- ✅ Expire a tombstone only after every node is guaranteed to know about it.

Note that this constraint breaks the cycle in the diagram of non-convergence above! It forbids the edges `S2 -&gt; S3`, `S5 -&gt; S6` and `S8 -&gt; S0`: each of those edges represents a tombstone being expired when at least one node is in a green `+` state and doesn&apos;t believe the tombstone exists!

We enforce the constraint by making the OR-Set semilattice a [lexical product](https://en.wikipedia.org/wiki/Lexicographic_order) semilattice: 

```
(causalContext, (adds, removes))
```

Unlike our previous *free product*, the `merge` operator for the lexical product only looks at its second field `(adds, removes)` when breaking ties on the first field `causalContext`:

$$
(cC_1, (a_1, r_1)) \sqcup (cC_2, (a_2, r_2)) =
\begin{cases}
  (cC_1, (a_1, r_1)) &amp; \text{if } cC_1 &gt; cC_2 \\\
  (cC_2, (a_2, r_2)) &amp; \text{if } cC_2 &gt; CC_1 \\\
    (cC_1 \sqcup cC_2, (a_1 \sqcup a_2, b_1 \sqcup b_2)) &amp; otherwise
\end{cases}
$$


Note that the `causalContext` is itself another semilattice! It tracks which operations have been observed system-wide. This tracking can be stale, but it is always a conservative lower bound. We can safely expire data from our OR set if it is older than our `causalContext`.

There are different implementations for `causalContext`, including *version vectors* or *causal graphs*. We&apos;ll work with version vectors since they&apos;re the most common.

&lt;details&gt;
&lt;summary&gt;Click to learn about version vectors.&lt;/summary&gt;

We begin by ensuring that each node maintains a *local clock* -- a counter that increments by 1 each time the node applies an operation or sends a message. (Note that a counter is also a semilattice, where the domain $S = \mathbb{N}$ is the natural numbers 0, 1, 2, ..., and the `merge` function is `max`.)
&lt;br /&gt;
&lt;br /&gt;

A *version vector* is a map from `nodeId`s to values from a counter lattice: it records the highest clock value a node has heard of *from each other node*. This map is itself a composite semilattice! Specifically:

- The domain $S$ is a map from `nodeId` (the key) to a value from the lattice $(\mathbb{N},$ `max`$)$ (the value)
- The `merge` function is simply key-wise application of the value lattice `merge` function (i.e., `max`). If a key is missing from one input to `merge`, we simply take its value from the other input.
&lt;/details&gt;

Notice what we did here: we formed a *composite* semilattice `(causalContext, (adds, removes))` out of very simple semilattice building blocks.
The `merge` functions of these lattices effectively invoke the encapsulated sub-lattice `merge` functions recursively.

*It really is lattices all the way down!*


#### Using Version Vectors for Safe Expiration
To use our version vectors, we will make a few small changes to our OR-set design:

1. Each node locally maintains an overall version vector containing the `merge` of *all* version vectors seen so far: this is typically called a *vector clock*. It represents a high-watermark of our local knowledge of global progress. 
2. When an item is deleted, its tombstone timestamp is set to the local vector clock.

We can now do expiration safely: tombstones are only expired if their timestamp is lower in the partial order than the local *vector clock*: if so, we can be sure that *every other node also knows about this tombstone, and will eventually expire it as well*.

## &lt;a id=&quot;op-based&quot;&gt;&lt;/a&gt;A Note on Op-Based CRDTS
As mentioned above, many CRDT fans like to talk about two &quot;different&quot; kinds of CRDTs: normal (&quot;state-based&quot;) semilattice CRDTs, and something called &quot;op-based&quot; CRDTs. *I&apos;m here to tell you that correct op-based CRDTs are also semilattices; the distinction is not fundamental.*

An &quot;op-based&quot; CRDT is just a particular class of semilattice. The state of an op-based CRDT represents a *partially-ordered log of operations* (opaque commands). The CRDT&apos;s job is to ensure that the partially-ordered log is consistent across nodes. 

The partial order among ops can be captured by each site tagging every new op it generates with a `causalContext` value. This ensures (1) that recipients of ops from node $n$ will have them ordered in the same way as $n$ did, and (2) operations *across* nodes are causally ordered, via the `causalContext`.

Specifically, the state $S$ of an op-based CRDT can simply be a *set* of `(causalContext, op)` tuples, with simple set-union as the `merge` function. The `causalContext` is ignored by the lattice `merge`, but carried along to preserve a consistent partial order of the log. One typical `causalContext` implementation is to use vector clock timestamps, with each node incrementing its entry in the vector clock for every op and message.

That&apos;s really all there is to an &quot;op-based&quot; CRDT: it&apos;s a grow-only set of causally-stamped commands. 

Typically, op-based CRDT designs assume that the log at each site is &quot;played&quot; (eagerly or lazily), by executing the ops in their causal partial order to materialize the local state. This is only required to support a &quot;read&quot; operation, and hence is effectively outside the scope of the CRDT math. Because causal order is only a partial order, different nodes could &quot;play&quot; some ops in different orders. As a result, op-based CRDT designs typically require the ops themselves to be mutually commutative. 

If an op-based CRDT has quiesced and propagated to every node, and the ops themselves are mutually commutative, then every node can &quot;play&quot; the log in some total order that respects the partial order, and all nodes will end up with a convergent outcome. 

To summarize: an op-based CRDT is still just a simple set semilattice! The only wrinkles are:
1. The items in the op-based CRDT set are stamped with causalContext to enable causally-ordered replay
2. For the ops to be meaningful at replay time, ops across sites should be commutative.

## 🪜 &lt;a id=&quot;building-on-an-existing-turtle&quot;&gt;&lt;/a&gt;You Can Build on a Turtle — But Know What It Carries
Sometimes, a system&apos;s lower layers provide additional guarantees that allow us to skip some details and rely on a turtle below us.

&gt; Example: If your network guarantees causal delivery, you can safely drop explicit causal tracking in your CRDT.

But beware: your CRDT is now resting on that turtle. If the network is not in fact behaving like a causal semilattice, your convergence proofs go out the window!

## 📌 Takeaways
- ✅ Every CRDT must be a (correct) semilattice
- ✅ Order comparisons must respect the partial order induced by `merge`.
- ✅ Model all necessary assumptions *inside* the lattice.
- ✅ Build on trusted turtles only when you know exactly what they can carry safely.

When you do all that?
&gt; **It&apos;s semilattices all the way down**.

That&apos;s math you can build on.

</content:encoded></item><item><title><![CDATA[A Run of CRDT Posts]]></title><description><![CDATA[Over the next few days, I'm going to post a number of observations about CRDTs: ~~Convergent~~ Conflict-free Replicated Data Types. These…]]></description><link>https://hellerstein.io/blog/crdt-intro/</link><guid isPermaLink="false">https://hellerstein.io/blog/crdt-intro/</guid><pubDate>Wed, 21 May 2025 00:00:00 GMT</pubDate><content:encoded>Over the next few days, I&apos;m going to post a number of observations about *CRDTs*: ~~Convergent~~ Conflict-free Replicated Data Types. These are data structures that aspire to help us with *coordination-free distributed programming*, a topic that interests me a lot. How can developers (or languages/compilers) deliver distributed programs that are *safe* or *correct* in important ways, without employing expensive mechanisms for *coordination* that make the global cloud run as slowly as a sequential computer?

In a nutshell, my take is that CRDTs are built on an elegant kernel, but offer a leaky abstraction that misleads a lot of developers -- and researchers. Understanding the ideas and problems of CRDTs is a great way to walk into this domain. I&apos;ll give an overview in this post, and the series of posts will go futher.

## CRDTs: Pros &amp; Cons (Lattices &amp; Lettuces?)
First, the elegant part, which I find very appealing: 

1. **Deep Roots**: CRDTs are based on *semilattices*, which are simple, abstract mathematical structures that have a `join` operator that is *associative, commutative, and idempotent*. The idea to use this for replicated data types goes back at least to work by [Baquero and Moura in 1997](https://gsd.di.uminho.pt/members/cbm/ps/scadt3.pdf). They deserve more citations for this! (HT [Conor Power](https://www.linkedin.com/in/conorpower23) for educating me about this; I believe he learned about it from [Marc Shapiro](https://www.lip6.fr/actualite/personnes-fiche.php?ident=P1450) of CRDT fame.) 

2. **Moar Algebra!**: The use of modern algebra as a building block for correctness in distributed systems and database systems is a wonderful direction for the field, and we&apos;re seeing more and more of this work in recent years. (See for example the [Simons&apos; Institute gathering](https://simons.berkeley.edu/workshops/logic-algebra-query-evaluation#simons-tabs) from a couple years back.) This semilattice/CRDT line of work was early, elegant and easy to understand. Lovely stuff.

Unfortunately there are few key problems that arise in common discussion of CRDTs:

1. **Drifting from Correctness**. As people walk away from the semilattice foundation, they can lose their moorings in correct math. This is entirely avoidable, and most experts know how to avoid bugs here, but the discussion often gets unnecessarily subtle ... in ways that confuse people.

2. **Unsafe to Use**. The algebra of semilattices has a single operator: `join`. Notably it doesn&apos;t have any operator that corresponds to *read* or *inspect*. In fact, CRDTs as described in the literature provide *absolutely no guarantees to readers*, so a &quot;proper&quot; CRDT implementation should *not allow reads!* Which is to say a correct CRDT is an entirely useless theoretical object. Yet people use CRDTs, inevitably reading/inspecting them in unsafe/non-deterministic ways. Worse, many developers *think* they&apos;re getting useful correctness guarantees from CRDTs, which they are not! The only safe thing to do with a CRDT is to leave it unexamined.

3. **Programmability Issues**. As *unreadable data types*, CRDTs can&apos;t be composed safely into useful programs. How in fact can we use them?  Ideally we&apos;d like a *language* that allows correct composition of CRDT building blocks. This is something folks have looked at in DSLs like [LVars](https://dl.acm.org/doi/abs/10.1145/2502323.2502326), [Bloom^L](https://dl.acm.org/doi/abs/10.1145/2391229.2391230), [Lasp](https://dl.acm.org/doi/abs/10.1145/2790449.2790525) and [Gallifrey](https://par.nsf.gov/biblio/10095545). There&apos;s still work to do to deliver those ideas to developers in a familiar frame, which is one goal of our [Hydro](https://hydro.run) library for Rust.

### My Take
So ... it&apos;s true that I&apos;m not a huge fan of CRDTs as a practical matter. But I think the core ideas are quite lovely, and the pitfalls are interesting and really educational for developers and researchers to understand.  Much respect to the folks who&apos;ve worked on CRDTs over the years, both for what they&apos;ve invented and the challenges they&apos;ve raised.

I learned a lot unpacking my discomfort with CRDTs over the years with my students, so my next few posts will hopefully expose and summarize some of what we learned along the way. You can decide whether this makes you more or less likely to use CRDTs in your code, but hopefully your decisions and ensuing heuristics will be better informed.</content:encoded></item><item><title><![CDATA[Looking Back to Look Ahead]]></title><description><![CDATA[This is the second of two background posts reflecting on my technical interests, to set some context for this blog. While there's no…]]></description><link>https://hellerstein.io/blog/looking-back/</link><guid isPermaLink="false">https://hellerstein.io/blog/looking-back/</guid><pubDate>Wed, 30 Apr 2025 00:00:00 GMT</pubDate><content:encoded>
This is the second of two background posts reflecting on my technical interests, to set some context for this blog.
While there&apos;s no breaking news here, I hope that outlining my long-term threads of work might spark interest or recognition. If something resonates, I’d love to hear what caught your eye.

## Looking back on research to date

Thanks largely to collaborations, I&apos;ve worked on a lot of different projects over the years. At times, I’ve felt a bit *too* scattered. Still, looking back, I see a through-line of long-term interests that have anchored my work and kept me engaged. These include formal programming models for distributed systems, the role of semantics in coordination, and the intersection of human insight and automated tools—threads that continue to shape my work today.

### Formal languages for distributed programming

One of the signatures of the database field is its bold embrace of high-level declarative languages, and the multi-decade challenge of translating from there down to efficient execution. I&apos;m glad to be part of a scientific culture that is willing to be patient and dig deep! One of the themes I&apos;ve pursued over time has been to take the lessons of declarative query languages and try to adapt them to other domains. I&apos;ve been at this for over two decades, and I think we&apos;re now ready to deliver some big practical payoffs outside the research world.

This theme began with a run of work on [Declarative Networking](https://dl.acm.org/doi/10.1145/1592761.1592785) in the oughts. We started pursuing a broader focus on general-purpose distributed computing in the 2010&apos;s. Along the way I also worked on SQL-based machine learning in the [MADlib](https://dl.acm.org/doi/10.14778/1687553.1687576) project, which exercised some of the same challenges.

Our early efforts in language design were ad-hoc extensions of datalog to networking, including [NDlog](https://dl.acm.org/doi/10.1145/1142473.1142485) for routing, and [Overlog](https://dl.acm.org/doi/10.1145/1095810.1095818) for overlay networks. As my ambitions expanded to designing a general-purpose distributed programming, my PhD students (an awesome trio of [Peter Alvaro](https://people.ucsc.edu/~palvaro/), [Tyson Condie](https://dl.acm.org/profile/81314493838) and [Neil Conway](https://www.neilconway.org/)) forced a pause. &quot;Why,&quot; they asked, &quot;would we design a new language before we try building things in the previous language?&quot; So, a bit painfully, they built a new Overlog runtime in Java, and reimplemented large chunks of Hadoop with it in a project we called [BOOM Analytics](https://dl.acm.org/doi/10.1145/1755913.1755937). Tyson also built an Overlog optimizer in Overlog called [Evita Raced](https://dl.acm.org/doi/10.14778/1453856.1453978).

Based on those experiences, we finally nailed our formal semantics with the [Dedalus](https://dl.acm.org/doi/10.1007/978-3-642-24206-9_16) language, which made time and space first class logical citizens, and allowed for the development of a formal model theoretic semantics. Dedalus was still a variant of datalog, which made it nice and clean for formal reasoning, but awkward for developers—its syntax was unfamiliar, the tooling was minimal, and the programming model felt restrictive for common tasks.

### Practical languages for distributed programming: Bloom and Hydro

Our first *practical* distributed programming language was [Bloom](https://bloom-lang.net), which stepped away from logic programming to embrace functional syntax and algebraic dataflow. Bloom was the first of our languages that was actually pretty fun to program in (though I was one of the few who actually had that experience!) Just as the Bloom PhD students were graduating and moving on to new challenges, I got distracted by adventures in startup land working on visualization, AI and program synthesis for data wrangling (see below). That put this agenda on the back burner for almost 10 years.

Over the past 5 years or so, a team of us has returned to attack high-level distributed programming with vigor—buoyed by renewed community interest in correctness, safety, and expressiveness, and a broader ecosystem shift toward systems languages like Rust. Our [Hydro](https://hydro.run) project is a serious effort to deliver on the agenda of general-purpose distributed programming, with new depth and relevance in the Rust ecosystem. This is both a passion project for me, and a serious software package targeted at real developers. I&apos;m sure I&apos;ll be blogging a lot about Hydro and related topics here over time, so I&apos;ll end the discussion here with that.

### CALM, distributed computing and coordination avoidance

I got started on high-level language design for the opportunity to demonstrate optimization opportunities. But it turned out that many of the ideas and lessons that arose were more about semantics than performance.

Just as [language shapes how we think about the world](https://en.wikipedia.org/wiki/Linguistic_relativity), programming languages shape how we think about computing. So maybe it&apos;s no surprise that designing new programming languages helped my group see things differently and ask new questions.

In my early days working on distributed computing, I got restless with that community&apos;s interests in optimizing protocols for tasks like consensus and fault tolerance. As an outsider, I was struck by how much complexity the distributed systems community was willing to embrace for relatively modest performance gains. My background in databases had trained me to seek orders-of-magnitude improvements, so I found myself wondering whether all that protocol engineering was truly essential. Rather than diving into consensus and coordination, I leaned toward avoiding them altogether. How far could I get without them?

That turned out to be a deep question, one that for some reason nobody had asked or answered in the literature. Our experience in Dedalus with &quot;fixing&quot; the bugs in ND/Overlog gave me a big hint: our use cases didn&apos;t need distributed systems coordination *if they were monotone*! (Roughly speaking, monotonicity means that once something becomes true, it stays true—an idea that’s easy to recognize in datalog languages but nearly invisible in imperative ones. That&apos;s the benefit of seeing differently!). The more I thought about it, this felt like a deeper insight, a case of *if and only if*. This grew into the [CALM Conjecture](https://dl.acm.org/doi/10.1145/1860702.1860704) which I presented in a keynote at PODS 2010, and which was first proven as the [CALM theorem](https://dl.acm.org/doi/10.1145/3369736) in 2011.

Even outside the CALM formalisms, monotonic thinking has informed a lot of systems work in my group—from the super-fast [Anna](https://dl.acm.org/doi/abs/10.1109/TKDE.2019.2898401) [autoscaling](https://www.vldb.org/pvldb/vol12/p624-wu.pdf) key-value store, to the [Cloudburst](https://dl.acm.org/doi/10.14778/3407790.3407836) stateful serverless platform, to the work [Peter Bailis](http://www.bailis.org/) led on [coordination avoidance for database transactions](https://dl.acm.org/doi/10.14778/2735508.2735509).

Perhaps most surprising was what [Michael Whittaker](https://mwhittaker.github.io/) showed in his PhD work with me: that coordination avoidance techniques could be leveraged to *scale coordination protocols themselves*. That twist led us to [Compartmentalized Paxos](http://www.vldb.org/pvldb/vol14/p2203-whittaker.pdf), and later to a set of [compiler optimizations in Hydro](https://dl.acm.org/doi/10.1145/3639257) that bring these ideas full circle.

And yes, that last bit shows that in the end I didn&apos;t avoid coordination research after all. But the will to procrastinate led to interesting exploration and invention along the way. I&apos;ve had this lesson on my web page since the 1990s:

&gt; &quot;Laziness in doing stupid things can be a great virtue&quot; -- James Hilton, *Lost Horizon*

My corollary might be this: procrastinating known smart things can also be a virtue!

### Human/AI collaborations in Data Wrangling

Early in my career, I got excited about building intuitive, interactive systems that let people explore data fluidly—a kind of game-like experience for analysis. (Yes, I too got interested in computer science via video games.) This theme started with my work on [Online Aggregation](https://dl.acm.org/doi/abs/10.1145/253260.253291), and continued with a range of efforts in interactive data manipulation.

Inspired by a suggestion from the great [Mike Carey](https://en.wikipedia.org/wiki/Michael_J._Carey_(computer_scientist)) during a seminar at Berkeley, [Vijayshankar Raman](https://www.linkedin.com/in/vijayshankar-raman-95363a/) and I began exploring interactive visual interfaces for data cleaning in the [Potter&apos;s Wheel](https://dl.acm.org/doi/10.5555/645927.672045) project. This work was motivated by a recurring theme I saw in both academia and failed startup ventures like Cohera and Swivel: people get stuck on mundane but necessary data transformation tasks. This was especially frustrating for quantitative professionals without programming backgrounds—an audience that computer science had largely underserved at the time.

After many years—and after significant progress in the field of data visualization—I had the opportunity to collaborate for the first time with the amazing [Jeff Heer](https://en.wikipedia.org/wiki/Jeffrey_Heer), who was then a rising star. The timing was serendipitous: enough had changed in the field that it felt like the right moment to return to the Potter&apos;s Wheel vision with new tools and energy. We were both excited to pick up where that work had left off. We recruited [Sean Kandel](https://www.linkedin.com/in/seankandel/) away from high frequency trading to enroll in the graduate program with Jeff at Stanford, and he built [Wrangler](https://dl.acm.org/doi/10.1145/1978942.1979444) and [Profiler](https://dl.acm.org/doi/10.1145/2254556.2254659) as vehicles for new ideas in this space, which included an embrace of AI assistance. Sean also kicked us into entrepreneurial mode, and we founded [Trifacta](https://en.wikipedia.org/wiki/Trifacta) to commercialize the work. This turned into a 10-year startup journey—one that brought new collaborators, new skills, and a crash course in navigating industry shifts. We rode the Big Data wave in and out, and eventually found ourselves in the SaaS era, helped along by Google white-labeling Trifacta as *Google Cloud Dataprep*. That move pushed us further into the future than we might have gone on our own.

Trifacta was very early in exploring questions that are now *au courant* in the LLM era: how do we design environments for humans to collaborate with AI on code and data? Our models and inference quality at the time were far more primitive, relying on heuristics and simple statistical techniques. But many of the UX ideas we explored remain strikingly relevant: empowering users to visually detect data quality issues, interact directly with data visualizations and grids, receive AI suggestions as both code and visual feedback, and iterate rapidly. What has changed is the sharpness of inference; what hasn&apos;t changed is the need to guide and constrain it. Whether the AI is 90% right or 75% right, it still needs to be scaffolded for humans to quickly evaluate and steer the process. These experiences continue to shape how I think about designing AI-powered developer tools—especially when it comes to interaction models, scaffolding, and trust. I wrote about our broad ideas in this space in the paper on [Predictive Interaction](https://idl.cs.washington.edu/files/2015-PredictiveInteraction-CIDR.pdf) and the Guide/Decide loop we were exploring in Trifacta. More recently, Berkeley&apos;s [EPIC Data Lab](https://epic.berkeley.edu) was conceived in part based on this experience, and my colleagues there continue to push in many related directions regarding low-code data management.

If you squint, this is another attack on high-level programming models—in this case &quot;low code&quot; approaches for non-programmers. In that lens, Trifacta was a low-code environment for doing AI-assisted program synthesis of data wrangling scripts. I fully expect that lessons from Wrangler, Trifacta, and Predictive Interaction will influence how we approach LLM-based assistance in Hydro, though Hydro is targeting more technical software engineers and is therefore less data-centric. I bet I&apos;ll have more to say on that front in the coming years.

### ... and so much more

It&apos;s hard to omit so many other topics that I&apos;ve worked with folks on over the years—especially because many of them were the work of amazing students and colleagues who I haven&apos;t had a chance to shout out to! I keep a [list of my PhD students](https://dsf.berkeley.edu/jmh/student.html) online. For the research topics, I&apos;ll add an appendix of sorts to the bottom of this post.

## Moving Forward

As I look ahead, I expect to dig even deeper into the Hydro agenda. On the pragmatic front, the codebase is maturing and ready to be tested in the wild—so it&apos;s time to find bold, high-impact use cases that will stretch our ideas and tools. On the research side, we&apos;re just beginning to scratch the surface of what&apos;s possible. One especially exciting direction is exploring how we can deliver a fundamentally new programming model for distributed systems in the era of AI-assisted development.

You can expect more posts here about those core Hydro themes, as well as the tangents and side quests that keep things interesting—both the breakthroughs and the frustrations. As Hydro transitions off campus, I may find myself with even more reason to document the journey. Either way, there’s a lot to say—and I’m looking forward to sharing it.

Thanks for reading. Onward!

## Topics for Another Day

It’s hard to write a recap like this without feeling the limits of the form. Nearly everything I’ve worked on has been deeply collaborative, and there are far more colleagues and students I admire than I’ve had space to name here. The topics and shoutouts above are a sampling, not a ranking—and many important threads didn’t make the main cut simply for reasons of narrative flow or space.

In that spirit, here are a few more topics I’ve worked on that continue to inform how I think about computing today:

- The **[Generalized Search Tree (GiST)](https://gist.cs.berkeley.edu/)** remains a core extensible indexing framework in PostgreSQL and powers spatial extensions like PostGIS. This work also led me into [Indexability Theory](https://dl.acm.org/doi/abs/10.1145/505241.505244) with my longtime mentor [Christos Papadimitriou](https://en.wikipedia.org/wiki/Christos_Papadimitriou).
- **Adaptive query processing of data streams**: Our work on [Eddies](https://dl.acm.org/doi/10.1145/335191.335420), [FLuX](https://dl.acm.org/doi/10.5555/894174), and the [TelegraphCQ](https://telegraph.cs.berkeley.edu/) project helped shape my thinking on stream-centric computing, a topic that is becoming increasingly relevant to general-purpose programming. The Telegraph team members went on to have broad impact across the database industry.
- **Peer-to-peer computing**: The [PIER](https://pier.cs.berkeley.edu/) project emerged during the early-2000s p2p wave. While the hype receded, the architectural ideas lingered. PIER got me thinking about the common ground between querying, indexing, routing, and overlay networks—components that all play roles in orchestrating distributed data and computation across space and time.
- **Sensor networks and probabilistic inference**: [TinyDB](https://telegraph.cs.berkeley.edu/tinydb/) shaped my early thinking about high-level programming of low-level devices, long before &quot;IoT&quot; was a thing. That line of work evolved into a collaboration with [Carlos Guestrin](https://guestrin.su.domains/) on distributed probabilistic inference—and helped pique my interest in AI after a discouraging first impression back in the era of expert systems and AI winter.
- **Metadata and data context**: Our [Ground](https://www.ground-context.org/) project explored lineage and metadata—i.e. *data context*—in our increasingly disaggregated era. Though we moved on, some of its ideas live on in [Datahub](https://datahubproject.io), thanks to our collaborator [Shirshanka Das](https://www.linkedin.com/in/shirshankadas).
- **Provenance for ML pipelines**: [Rolando Garcia](https://rlnsanz.github.io/) did his thesis work with us on [Flor](https://github.com/ucbrise/flor), a system for *hindsight logging* in long-running training jobs. He continues to push this space forward—see his [recent piece](https://arxiv.org/abs/2408.02498) for where it’s going next.
</content:encoded></item><item><title><![CDATA[Context for a New Home]]></title><description><![CDATA[Time to get blogging again. After a long run with Data in Beta, it's nice to have a fresh start. WordPress was feeling clunky, and over time…]]></description><link>https://hellerstein.io/blog/new-home/</link><guid isPermaLink="false">https://hellerstein.io/blog/new-home/</guid><pubDate>Sun, 27 Apr 2025 00:00:00 GMT</pubDate><content:encoded>
Time to get blogging again. After a long run with [Data in Beta](https://databeta.wordpress.com/), it&apos;s nice to have a fresh start. WordPress was feeling clunky, and over time the title took on unintended connotations. So I’m starting over—lighter, cleaner, and more grounded here on GitHub Pages.  

The ideas won’t be any more “finished” than before, but it feels like a good time to shed some baggage and keep moving.  

I&apos;ll still be blogging mostly about thoughts that come up in research and development with my team.  
If you&apos;re into programming, computation, data management, or distributed systems,  
you might find things here to interest you over time.  

---

## Research Roots

To set some context for what you&apos;ll find on this blog, here&apos;s a bit about where I’m coming from—intellectually and professionally.  

I was trained as a database researcher back in my salad days. Out of college, I interned with the storied database group at IBM Almaden—the same team who brought us System R, which begat R*, which begat Starburst, the project I worked on.  

I then did my MS with the amazing Postgres team at Berkeley, and continued working on Postgres with them as I did a PhD with the famed Wisconsin database mafia.  

In retrospect, I was very fortunate to do a tour of duty with each of the most influential database groups of the time. I learned a ton.  

During that training I met some outsized personalities and grew a thicker skin, which has undoubtedly had both positive and negative impacts on my professional life. That said, all my mentors were incredibly kind and supportive to me personally, and I&apos;ll always be paying forward their influences—especially [Meichun Hsu](https://www.linkedin.com/in/meichun-hsu-0a72968), [Hamid Pirahesh](https://www.linkedin.com/in/hamid-pirahesh-38368010/), [Mike Stonebraker](https://en.wikipedia.org/wiki/Michael_Stonebraker), and [Jeff Naughton](https://en.wikipedia.org/wiki/Jeffrey_Naughton).  

---

## The Benefits of a Database Upbringing

Database research was—and still is—my home research community. It&apos;s a great space: a cross-cutting area of computing that has, from its beginnings, spanned academia and industry, theory and practice.  

Data management provides a context to work on pretty much every computing topic imaginable. But database folks see the world of computing a bit differently: our primary focus is on the data that moves around, rather than the silicon resources of a computer. This often frees us up to take a broader view.  

There&apos;s a meme in the &quot;Systems&quot; community: for any given topic, someone says “I think database people already solved that problem.”  
And y’know … it&apos;s not wrong! 🙂  

DB folks were among the first in software to tackle service-oriented computing at scale, with correctness and fault tolerance guarantees, and an eye toward serving a wide range of users—not just hobbyists and hackers.  

The goalposts have shifted since the 1970s, of course, and sometimes being *early* to a technology can be a liability in the business world. But much less so in research!  

It&apos;s kind of amazing how prescient the DB folks were in the 1970s and 1980s (before my time!) about the problems worth solving in computer science. And it&apos;s not just the applied folks—there&apos;s also a ton of database theory work that keeps coming back in new contexts.  

---

## Cross-Pollination

Over the years, I’ve had the good fortune to collaborate with friends from all corners of computing: experts in distributed systems, programming languages, HCI, AI, networking, and theory.  

I&apos;ve always liked working with people who can teach me new things, and I enjoy having a broad portfolio of topics to keep me curious.  

Cross-area collaboration pulls you away from the center of your home field—and on the whole, I’ve been glad about that. Many of the most interesting places are away from the center.  

---

## Outside the Box

Topic areas aside, I generally prefer to work on problems that most folks are *not* working on.

Hot topics drive scientists to race for discovery. Lots of people like racing—especially because the fastest racer gets a big medal! But in most cases, if the winner had tripped along the way, someone else would have replaced them with no appreciable difference in outcome.  

I find that highly demotivating, particularly in a field where the main goal is innovation.

I don’t like to race. I’d rather explore and invent.  

---

## Coming Up

In the next post, I’ll dig into some of the research that’s grown out of this perspective—ranging from language design and distributed consistency to data visualization, AI-based systems and beyond.
</content:encoded></item></channel></rss>