---
title: "Tips on Research"
date: 2025-06-27
order: 2
coverImage: ./these-five-tricks.png
---

As a complement to my last post, I thought I'd write a follow-up with some constructive advice. 
No point complaining about negativity if you don't offer some positive alternatives!

# Five Tips for Doing Your Best Research

Rather than opine about research topics, which are always changing, I thought I'd offer advice on research processes. No doubt a lot of this is conventional wisdom, but I came to these conclusions based on my own career experience. Maybe some of this will be useful to some of you who are earlier on in your journey. Your mileage may vary.


1. **Follow Your Muse, but Evaluate Humbly**. Pursue topics that fascinate you; the best work comes from enthusiasm. But also build in mechanisms that force you to be clear-headed about assessing the impact of your work over time! Evaluate on a timescale that suits your career and work (5-year windows align well with PhD student lifecycles), and humbly move on from topics where the impact isn't what you wanted. Time spent in industry—especially entrepreneurship—is helpful in learning this discipline; the market is an efficient (heartless!) teacher of lessons in adaptability and humility, as anyone whose startup has "pivoted" will share. Changing course can be scary, but sometimes it sets you free to shine again.

2. **Explore and Exploit**: After my first few years in research, I started deliberately trying to invest my research time in a portfolio of a few "long plays" (in my case, applying declarative/dataflow programming to a variety of other domains) and a larger number of shorter but diverse excursions. Reinforcement learning folks might call this "explore vs. exploit", and clearly one should do some of both. Connecting back to the previous point, it's the long plays that benefit the most from deliberate reflection; the short ones have agility built in.

3. **Pick Topics that Leverage Your Working Style**: Pick topic areas that favor a research style that fits your personality. For example, working on AI-related topics right now demands that you produce a lot of quick-fire results in a tightly competitive arena. That requires an restless competitive streak: reading a ton, being quick to change, and doing research in relatively short bites on very popular topics. By contrast, meaningful systems work requires an investment of many years of engineering and teamwork, during which there will be fallow periods of publication. In that space, you need patience, good taste and self-confidence, because you don't get to change your mind nearly as often. There's no right answer here—you might enjoy a mixture, and one style is not inherently better than another. But it's good to make sure that your personal working style matches your topic selection. In your early days, finding role models in the literature can help—again, one role model may be quite different from another, so choose what appeals to you and reassess over time.

4. **Collaborate with Complementary Experts**. It's good intellectual nutrition to collaborate with experts in a variety of other fields. A lot of the best research opportunities are at the seams between traditional fields, and it's more educational and fun to work with people who know and think about things different than your experience.
For faculty, I suggest spending ~5 years co-advising Ph.D. students with people in another field, whether that's across or outside CS. Then consider trying a new collaboration in a different field thereafter. 
Doing this will broaden your horizons, and teach you more about your own strengths: the ones that come from your education in your home field, and the ones that come from your personal research style and talents.

5. **For Topic Selection, Do Your (Qualitative) Research**. This is maybe the least common advice in this list. To choose important problems—especially in user-facing areas—consider learning how to do qualitative research methods like interview studies, to figure out empirically what problems will have impact. I've been involved in doing this twice (once for [Enterprise Data Analytics](http://vis.stanford.edu/files/2012-EnterpriseAnalysisInterviews-VAST.pdf), and more recently for [Machine Learning Engineering](https://dl.acm.org/doi/abs/10.1145/3653697)). In both cases, the interview studies led to interesting and highly relevant follow-on constructive work, and the papers describing the studies and results were themselves well received: both won awards. Be aware: this is a lot of work to do well! (To be clear, in the cases above that work was not done by me—it was done by amazing students like [Sean Kandel](https://en.wikipedia.org/wiki/Sean_Kandel), [Rolando Garcia](https://rlnsanz.github.io/) and [Shreya Shankar](https://www.sh-reya.com/)).  Note that versions of this approach are now standard practice for entrepreneurs, and that's an area where we can learn from industry practices as well as social scientists. See the book [The Mom Test](https://www.momtestbook.com/) for a distilled discussion.

# Caveat
I'll close with a standard warning I give when people ask me for advice on starting companies. Most entrepreneurs wildly overfit their advice to their own narrow experience. But it's hard to experience a broad sample as a founder; some folks who dish out advice are more self-aware about that than others. The overfitting is more extreme in the startup world than academia, but the theme remains. 

So... take my advice for what it's worth (hint: this blog is free!) and go ask a lot of other people for theirs too.
